{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div class=\"clearfix\" style=\"padding: 10px; padding-left: 0px\">\n",
    "<img src=\"https://raw.githubusercontent.com/jupyter/nature-demo/master/images/jupyter-logo.png\" width=\"150px\" style=\"display: inline-block; margin-top: 5px;\">\n",
    "<img src=\"http://spark-mooc.github.io/web-assets/images/ta_Spark-logo-small.png\" width=\"150px\" class=\"pull-right\" style=\"display: inline-block; margin: 0px;\">\n",
    "</div>\n",
    "\n",
    "# Welcome to Example Platform-library PySpark Notebook\n",
    "\n",
    "It's a shared Jupyter server for you to learn and try out Jupyter notebook and perform interactive data analytics using PNDA platform libraries.\n",
    "\n",
    "In this example notebook, **JsonDataHandler**, a data handler implementation based on the assumption that the 'rawdata' field wrapped in Pnda avro record is a well-formatted in JSON.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "To run the codes below:\n",
    "\n",
    "1. Click on the cell to select it.\n",
    "2. Press `SHIFT+ENTER` on your keyboard or press the play button (<button class='fa fa-play icon-play btn btn-xs btn-default'></button>) in the toolbar above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate sample datasets ###\n",
    "\n",
    "If you don't have existed datasets, there are two ways to generate sample datasets:\n",
    " * use data generation tool\n",
    " * use embedded cell in this notebook\n",
    "\n",
    "Data generation tool is pre-installed on this node at `/home/cloud-user/data_generator.py`. \n",
    "\n",
    "<div class=\"alert alert-warning\" role=\"alert\" style=\"margin: 10px\">\n",
    "<p>** Usage **</p>\n",
    "```\n",
    "./data_generator.py --hosts '<host1_ip>,<host2_ip>'\\\n",
    "                    --metrics '<metric1>,<metric2>'\\\n",
    "                    --year <year>\\\n",
    "                    --month <month>\\\n",
    "                    --day <day of the day>\\\n",
    "                    --hour <hour of the day>\n",
    "```\n",
    "<p>\n",
    "[NOTE: if year|month|day|hour option is ignored, the script will extract values from current system time.]\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Alternative, you can simply run the cell below to generate sample network usage datesets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Example 1: ** Generate sample network usage datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/user/pnda/PNDA_datasets/datasets/source=test/year=2016/month=04/day=26/hour=16/f8236764-222c-4fd1-a873-61a71c28f6a3.avro'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import avro.schema\n",
    "import avro.io\n",
    "import io\n",
    "import datetime\n",
    "import uuid\n",
    "import time\n",
    "import sys\n",
    "import pyhdfs\n",
    "\n",
    "from random import randint\n",
    "from avro.datafile import DataFileWriter\n",
    "from avro.io import DatumWriter\n",
    "from argparse import RawTextHelpFormatter\n",
    "\n",
    "fs = pyhdfs.HdfsClient(hosts='hdfs-namenode:50070', user_name='pnda')\n",
    "\n",
    "def generate_sample_datasets (host_ips, metric_ids, year, month, day, hour):\n",
    "    avro_schema = ''\n",
    "    #load data from hdfs\n",
    "    with fs.open('/user/pnda/PNDA_datasets/datasets/.metadata/schema.avsc') as f:\n",
    "        avro_schema = f.read()\n",
    "        schema = avro.schema.parse(avro_schema)\n",
    "        bytes_writer = io.BytesIO()\n",
    "        encoder = avro.io.BinaryEncoder(bytes_writer)\n",
    "        #create hdfs folder structure\n",
    "        dir = create_hdfs_dirs (year, month, day, hour)\n",
    "        filename = str(uuid.uuid4()) + '.avro'\n",
    "        filepath = dir + filename\n",
    "        tmp_file = '/tmp/' + filename\n",
    "        writer = DataFileWriter(open(tmp_file, \"w\"), DatumWriter(), schema)\n",
    "        start_dt = datetime.datetime(year, month, day, hour, 0, 0) \n",
    "        start_ts = int(time.mktime(start_dt.timetuple()))\n",
    "        end_dt = start_dt.replace(hour=hour+1)\n",
    "        end_ts = int(time.mktime(end_dt.timetuple()))\n",
    "\n",
    "        for ts in xrange(start_ts, end_ts, 1):\n",
    "            #generate random pnda record on per host ip basis\n",
    "            for host_ip in host_ips:\n",
    "               record = {}\n",
    "               record['timestamp'] = (ts * 1000)\n",
    "               record['src'] = 'test'\n",
    "               record['host_ip'] = host_ip\n",
    "               record['rawdata'] = generate_random_metrics(metric_ids)\n",
    "               #encode avro\n",
    "               writer.append(record)\n",
    "        writer.close()\n",
    "        fs.copy_from_local(tmp_file, dir+filename)\n",
    "        return filepath\n",
    "\n",
    "def generate_random_metrics (metric_ids):\n",
    "    raw_data = {}\n",
    "    for id in metric_ids:\n",
    "        raw_data[id] = str(randint(0, 100))\n",
    "    return json.dumps(raw_data).encode('utf-8')\n",
    "\n",
    "def create_hdfs_dirs (year, month, day, hour):\n",
    "    dir = \"/user/pnda/PNDA_datasets/datasets/source=test/year=%0d/month=%02d/day=%02d/hour=%02d/\" % (year, month, day, hour)\n",
    "    fs.mkdirs(dir)\n",
    "    return dir    \n",
    "\n",
    "#example host ips (update as you wish)\n",
    "host_ips = ['10.0.0.1', '10.0.0.2', '10.0.0.3']\n",
    "#example metric list (update as you wish)\n",
    "metrics=['in_bytes', 'out_bytes', 'in_pks', 'out_pks']\n",
    "#generate example datasets (update year, month, day, and hour as you wish)\n",
    "generate_sample_datasets(host_ips, metrics, 2016, 4, 26, 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play with RDD ###\n",
    "RDD can be created automatically using PNDA platform libary. This allows data exploration using low-level RDD APIs.\n",
    "\n",
    "** Example 2: ** Create an instance of JsonDataHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cm_host'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d12cba48f4bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplatformlibs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson_data_handler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJsonDataHandler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhandler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJsonDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"year=2016/month=04/day=26/hour=16\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/platformlibs-0.6.8-py2.7.egg/platformlibs/json_data_handler.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, spark_context, datasource, path)\u001b[0m\n\u001b[1;32m     36\u001b[0m                              \u001b[0mspark_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                              \u001b[0mdatasource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                              path)\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/platformlibs-0.6.8-py2.7.egg/platformlibs/data_handler.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, spark_context, datasource, path)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hdfs_root_uri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/platformlibs-0.6.8-py2.7.egg/platformlibs/data_handler.pyc\u001b[0m in \u001b[0;36m_load_schema\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[1;32m    107\u001b[0m         \u001b[0mschema_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}/user/pnda/PNDA_datasets/datasets/'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                       \u001b[0;34m'.metadata/schema.avsc'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhdfs_root_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspark_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtextFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/platformlibs-0.6.8-py2.7.egg/platformlibs/data_handler.pyc\u001b[0m in \u001b[0;36mhdfs_root_uri\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hdfs_root_uri\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mcm_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/etc/platformlibs/platformlibs.ini'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hdfs_root_uri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hdfs_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm_conf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cm_host'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcm_conf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cm_user'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcm_conf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cm_pass'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcm_conf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hadoop_distro'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hdfs_root_uri\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cm_host'"
     ]
    }
   ],
   "source": [
    "from platformlibs.json_data_handler import JsonDataHandler\n",
    "handler = JsonDataHandler(sc, \"test\", \"year=2016/month=04/day=26/hour=16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Example 3: ** Simple RDD operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "rdd = handler.rdd\n",
    "# print total nubmer of records\n",
    "print rdd.count()\n",
    "\n",
    "# print one record\n",
    "pprint.pprint(rdd.take(1))\n",
    "\n",
    "# use MapR function to print list of unique router ips\n",
    "host_ips = rdd.map(lambda x: x['host_ip']).distinct().collect()\n",
    "pprint.pprint(host_ips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Challenge 1: ** How many unique metrics of all routers have been collected? What are they?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speculate your anwser here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize high-level statistics ###\n",
    "PNDA platform library provide functions to return high-level statistics on per host basis using `list_host_ips()` and on per metric basis using `list_metric_ids()`.\n",
    "\n",
    "** Example 4: ** Plot a bar chart to show the total number of records per host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot simple bar chart\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# query host IPs\n",
    "host_stats = handler.list_host_ips()\n",
    "host_ips = []\n",
    "counts = []\n",
    "for stat in host_stats:\n",
    "    host_ips.append(stat[0])\n",
    "    counts.append(stat[1])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "x = np.arange(len(host_ips))\n",
    "rects = ax.bar(x, counts, color='y')\n",
    "plt.xticks(x+0.5, host_ips, rotation=45) \n",
    "\n",
    "def autolabel(rects):\n",
    "    # attach 'counts' labels\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n",
    "                '%d' % int(height),\n",
    "                ha='center', va='bottom')\n",
    "autolabel(rects) # add label on bar\n",
    "plt.ylabel('counts')\n",
    "plt.title('Statistics of hosts')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Challenge 2: ** Generate a bar chart to show total number of records per metric of host 10.0.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speculate your anwser here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing interactive UI ###\n",
    "Interactivity introduction to your notebook can be done by adding widgets provided in the `ipywidgets` package. Each widget consists of two parts: the UI element (e.g. Text Input, sliding bar, etc.) and an event handler. \n",
    "\n",
    "** Example 5: ** Interactive visualization of total number of records per metric of a particular host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from ipywidgets import *\n",
    "from IPython.display import display\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "options= ['--select--'] + sorted(host_ips)\n",
    "selected_host = \"--select--\"\n",
    "\n",
    "host_ip_widget = widgets.Dropdown(description='Host IP:', width=100, options=options)\n",
    "display(host_ip_widget)\n",
    "# diplaying the limits input widget:\n",
    "limits_input = widgets.Text(description=\"limits :\", width=200)\n",
    "display(limits_input)\n",
    "# preparing a container to put in the created checkbox per host ip\n",
    "checkboxes = []\n",
    "cb_container=widgets.HBox()\n",
    "display(cb_container)\n",
    "\n",
    "# add button that updates the graph based on the checkboxes\n",
    "button = widgets.Button(description=\"submit\")\n",
    "display(button)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    selected_host = host_ip_widget.value\n",
    "    \n",
    "    def autolabel(rects):\n",
    "        # attach 'counts' labels\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n",
    "                    '%d' % int(height),\n",
    "                    ha='center', va='bottom')\n",
    "    limit = -1\n",
    "    if limits_input.value:\n",
    "        limit = int(limits_input.value)\n",
    "        \n",
    "    filters={}\n",
    "    metrics = None\n",
    "    if selected_host != \"--select--\":\n",
    "        filters['host_ips']=[selected_host] \n",
    "        metrics = handler.list_metric_ids(limit=limit, filters=filters)\n",
    "        if len(metrics) > 0:\n",
    "            host_ip = metrics[0][0]\n",
    "            metric_stats = metrics[0][1]\n",
    "\n",
    "            metric_ids=[]\n",
    "            metric_counts=[]\n",
    "            for stat in metric_stats:\n",
    "                metric_ids.append(stat[0])\n",
    "                metric_counts.append(stat[1])\n",
    "            x = np.arange(len(metric_ids))\n",
    "            fig, ax = plt.subplots(figsize=(15, 8))\n",
    "            metric_rects = ax.bar(x, metric_counts, color='y')\n",
    "            plt.xticks(x+0.5, metric_ids, rotation='vertical') \n",
    "            plt.ylabel ('counts')\n",
    "            patch = mpatches.Patch(color='y', label=host_ip)\n",
    "            plt.legend(handles=[patch])\n",
    "            autolabel(metric_rects)\n",
    "            plt.draw()\n",
    "    else:\n",
    "        print \"Please select a host ip from dropdown list.\"\n",
    "        \n",
    "button.on_click(on_button_clicked)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Example 6: ** Interactive time series visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "from ipywidgets import *\n",
    "from operator import add\n",
    "from IPython.display import display\n",
    "import calendar\n",
    "import time\n",
    "\n",
    "dateFormatString = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "colors=['b', 'c', 'y', 'm', 'r']\n",
    "\n",
    "# displaying the metric id input widget\n",
    "metric_id_input = widgets.Text(description=\"metric id:\", width=200)\n",
    "display(metric_id_input)\n",
    "\n",
    "host_ip_input = widgets.Text(description=\"host ip:\", width=200, value='edit and hit to add')\n",
    "display(host_ip_input)\n",
    "\n",
    "#preparing the plot \n",
    "plots = dict()  \n",
    "\n",
    "#preparing a container to put in created checkbox per host ip\n",
    "checkboxes = []  \n",
    "cb_container = widgets.HBox()  \n",
    "display(cb_container)\n",
    "\n",
    "#preparing update button\n",
    "update_button = widgets.Button(description=\"Update\")\n",
    "\n",
    "#normalise data with 5-min interval\n",
    "def post_process(data):\n",
    "    def f(x): \n",
    "        sum_val = 0\n",
    "        for val in x:\n",
    "            sum_val = sum_val + x[0][1]\n",
    "        return sum_val\n",
    "    data_rdd = sc.parallelize(data).map(lambda x: (x[0], int(x[1]))).foldByKey(0, add).sortBy(lambda x: x[0]).groupBy(lambda x : (calendar.timegm(time.strptime(datetime.datetime.fromtimestamp(x[0]/1000).strftime('%Y-%m-%d %H:%M:%S'), dateFormatString))/(5*60))).map(lambda x : (x[0],list(x[1]))).mapValues(f).map(lambda x: (datetime.datetime.fromtimestamp(x[0] * 6*50), x[1]))\n",
    "    return data_rdd.keys().collect(), data_rdd.values().collect()\n",
    "\n",
    "#function to deal with the added host ip\n",
    "def handle_submit(sender):  \n",
    "    exists = False\n",
    "    for cb in checkboxes:\n",
    "        if cb.description is host_ip_input.value:\n",
    "            exists = True\n",
    "    if not exists and len(checkboxes)<5:\n",
    "        #add a new checkbox for the new host ip\n",
    "        checkboxes.append(widgets.Checkbox(description = host_ip_input.value, value=True, width=90))\n",
    "        cb_container.children=[i for i in checkboxes]\n",
    "        if len(checkboxes) == 1:\n",
    "            display(update_button)\n",
    "\n",
    "#function to deal with the checkbox update button       \n",
    "def on_button_clicked(b): \n",
    "    filters = {}\n",
    "    filters['metrics']=[metric_id_input.value]\n",
    "    host_ips = []\n",
    "    for c in cb_container.children:\n",
    "        if c.value:\n",
    "            host_ips.append(c.description)            \n",
    "    filters['host_ips'] = host_ips\n",
    "\n",
    "    results = handler.execute_query(filters=filters)\n",
    "\n",
    "    i=0\n",
    "    if len(results) > 0:\n",
    "        # Plot things...\n",
    "        fig = plt.figure(figsize=(15, 8))\n",
    "        ax=fig.add_subplot(111)\n",
    "        for result in results:\n",
    "            label = result[0][1]\n",
    "            timestamps, values = post_process(result[1])\n",
    "            ax.plot_date(timestamps, values, c=colors[i], label=label)\n",
    "            i=i+1\n",
    "        ax.xaxis.set_major_formatter(matplotlib.dates.DateFormatter(\"%H:%M:%S\"))\n",
    "        plt.ylabel(metric_id_input.value)\n",
    "        plt.xlabel(\"time of the day\")\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.gray()    \n",
    "        plt.show()\n",
    "        \n",
    "update_button.on_click(on_button_clicked)  \n",
    "host_ip_input.on_submit(handle_submit)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Challenge 3: ** generate scatter plots to show packet/bytes drops (e.g. use in_byte metric) of a partiular host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speculate your anwser here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark2/Python2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "widgets": {
   "state": {
    "1557e450223e4dde8c2413a5ee83e705": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "1afdbacd1b0b478aa01978edac6c190a": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "1ba2b95d0e4d4a26a7aa819dc8534c6a": {
     "views": []
    },
    "2db1cd0c66dd4e8196a900db826d64c8": {
     "views": []
    },
    "38670bab911f412191a9b3deb84babc7": {
     "views": []
    },
    "461bb60055dd4397b778a407640d1d99": {
     "views": []
    },
    "533f372af51e4cb79e2122e986d701df": {
     "views": []
    },
    "561a2c0073014a1d8cad39649bc96573": {
     "views": []
    },
    "58ce38b80de34d6e82a4d160febff999": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    },
    "633ca203e85541b59f9131e83f6b12bb": {
     "views": []
    },
    "634e89cc27f14c5eb125d8294ab0e262": {
     "views": []
    },
    "63bf2949f1ab4cdbb73d1d0d6d20dbd0": {
     "views": []
    },
    "657e67c80c174b04bbd1f8cee14674ef": {
     "views": []
    },
    "6b7ff28cf96145abbcb000a6d784b58c": {
     "views": []
    },
    "7cf1b6bb25d841b0b83bf337300df6fd": {
     "views": []
    },
    "810c709e9cc84968a1c20d1d13db8acf": {
     "views": []
    },
    "a2439b82434d41a3b63efdbf3eee6519": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "a4848088511d42379c3daf05b7150343": {
     "views": []
    },
    "ac64a66ddb0e4cf9bd3cd37cf4275b28": {
     "views": []
    },
    "ade75b3524bc42d39979108791ac27e0": {
     "views": []
    },
    "aeac437c13634b02be44b86ce14a16d7": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    },
    "b2d5229dfa0c4bc093922e6fd9afbd7a": {
     "views": []
    },
    "b81aa794d7d74402bb68519be24bb444": {
     "views": []
    },
    "bd62dae252ac444fbc377bec6458eb6b": {
     "views": []
    },
    "c6d9fa2d6f2a4f0fb0b662d6bd89c6a4": {
     "views": []
    },
    "cc93c8dda54d4f139f41b42c3dba67ad": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "ce3a67a85dcf4cefbe5fa3e9e27644d8": {
     "views": []
    },
    "df0a9835ec7c49ffaa7992c919a6ddcf": {
     "views": []
    },
    "e61981d0808e4ce1ac91ad16d8f3b55f": {
     "views": []
    },
    "e87b1311dbde4cd0bc020eb484d72f5b": {
     "views": []
    },
    "e9353bafbf6a4a9b8b9de0747078720f": {
     "views": []
    },
    "f0874b40c3da49fbb514e3f9f2047df3": {
     "views": []
    },
    "f2bb960e4fc2454fa1be3b679c7fd078": {
     "views": []
    },
    "fe575e9009c54084bd0a27bdd4c03382": {
     "views": []
    }
   },
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
